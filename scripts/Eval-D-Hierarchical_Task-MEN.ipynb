{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_path = \"../utils/\"\n",
    "corpus_path = \"../datasets/final_dataset_v4_to_publish/\"\n",
    "test_gs_path = corpus_path + \"test/testX.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 08:30:28.812239: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4812: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Auxiliary components\n",
    "import sys\n",
    "sys.path.insert(0, utils_path)\n",
    "from nlp_utils import *\n",
    "\n",
    "RES_DIR = \"../results/CodiEsp/final_exec/\"\n",
    "\n",
    "TYPE_ANN = \"DIAGNOSTICO\"\n",
    "TYPE_TASK = TYPE_ANN[0].lower()\n",
    "\n",
    "# GS data\n",
    "df_test_gs = format_codiesp_x_gs(test_gs_path)\n",
    "\n",
    "codes_d_path = corpus_path + \"codiesp_codes/codiesp-\" + TYPE_TASK.upper() + \"_codes.tsv\"\n",
    "valid_codes = set(pd.read_csv(codes_d_path, sep='\\t', header=None, \n",
    "                                  usecols=[0])[0].tolist())\n",
    "valid_codes = set([x.lower() for x in valid_codes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ner_norm_performance(model_name, arr_execs):\n",
    "    \"\"\"\n",
    "    Sanity-check procedure that prints the NORM performance of each single model execution.\n",
    "    \"\"\"\n",
    "    for i_exec in arr_execs:\n",
    "        print(\"Exec \" + str(i_exec) + \":\")\n",
    "        df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "        print(\"NORM performance:\", calculate_codiesp_x_metrics(\n",
    "            df_gs=df_test_gs[df_test_gs['label_gs'] == TYPE_ANN], \n",
    "            df_pred=format_codiesp_x_pred_df(\n",
    "                df_run=df_test_preds,\n",
    "                valid_codes=valid_codes\n",
    "            )\n",
    "        ), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(dict_names_execs, \n",
    "                      df_gs=df_test_gs,\n",
    "                      round_n=3, multi_task=False):\n",
    "    \"\"\"\n",
    "    Generate a pd.DataFrame with the statistics of the performance of each model.\n",
    "    \n",
    "    dict_names_execs: each key is a string with the model name, and \n",
    "                      each value is a list with the execs of the corresponding model.\n",
    "    \"\"\"\n",
    "    res_dict = {}\n",
    "    for model_name in dict_names_execs:\n",
    "        p_res, r_res, f1_res = [], [], []\n",
    "        for i_exec in dict_names_execs[model_name]:\n",
    "            if multi_task:\n",
    "                df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_multi_task_ner_\" + str(i_exec) + \"_\" + \\\n",
    "                    TYPE_TASK + \"_hier_task_cls_\" + str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "            else:\n",
    "                df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                    str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "            p, r, f1 = calculate_codiesp_x_metrics(\n",
    "                df_gs=df_gs[df_gs['label_gs'] == TYPE_ANN], \n",
    "                df_pred=format_codiesp_x_pred_df(\n",
    "                    df_run=df_test_preds,\n",
    "                    valid_codes=valid_codes\n",
    "                )\n",
    "            )\n",
    "            p_res.append(p)\n",
    "            r_res.append(r)\n",
    "            f1_res.append(f1)\n",
    "        p_res_stat = pd.Series(p_res).describe()\n",
    "        r_res_stat = pd.Series(r_res).describe()\n",
    "        f1_res_stat = pd.Series(f1_res).describe()\n",
    "        res_dict[model_name] = {\"P_avg\": round(p_res_stat['mean'], round_n), \"P_std\": round(p_res_stat['std'], round_n), \n",
    "                                \"P_max\": round(p_res_stat['max'], round_n),\n",
    "                                \"R_avg\": round(r_res_stat['mean'], round_n), \"R_std\": round(r_res_stat['std'], round_n), \n",
    "                                \"R_max\": round(r_res_stat['max'], round_n),\n",
    "                                \"F1_avg\": round(f1_res_stat['mean'], round_n), \"F1_std\": round(f1_res_stat['std'], round_n), \n",
    "                                \"F1_max\": round(f1_res_stat['max'], round_n)}\n",
    "    return pd.DataFrame(res_dict, index=[\"P_avg\", \"P_std\", \"P_max\", \n",
    "                                         \"R_avg\", \"R_std\", \"R_max\", \n",
    "                                         \"F1_avg\", \"F1_std\", \"F1_max\"]).transpose()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_paper(df_res):\n",
    "    arr_metrics = [\"P\", \"R\", \"F1\"]\n",
    "    arr_cols = []\n",
    "    for metric in arr_metrics:\n",
    "        df_res[metric + '_avg_std'] = df_res.apply(\n",
    "            lambda x: \".\" + str(x[metric + '_avg']).split('.')[-1] + \" Â± \" + \\\n",
    "                \".\" + str(x[metric + '_std']).split('.')[-1], \n",
    "            axis=1\n",
    "        )\n",
    "        df_res[metric + '_max'] = df_res[metric + '_max'].apply(\n",
    "            lambda x: \".\" + str(x).split('.')[-1]\n",
    "        )\n",
    "        arr_cols += [metric + '_avg_std', metric + '_max']\n",
    "    return df_res[arr_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec 1:\n",
      "NORM performance: (0.6685, 0.5662, 0.6131)\n",
      "\n",
      "Exec 2:\n",
      "NORM performance: (0.6641, 0.5676, 0.612)\n",
      "\n",
      "Exec 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORM performance: (0.6912, 0.5654, 0.622)\n",
      "\n",
      "Exec 4:\n",
      "NORM performance: (0.6881, 0.5598, 0.6174)\n",
      "\n",
      "Exec 5:\n",
      "NORM performance: (0.6795, 0.5609, 0.6145)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "m_name = \"xlmr\"\n",
    "execs = [1, 2, 3, 4, 5]\n",
    "\n",
    "check_ner_norm_performance(model_name=m_name, arr_execs=execs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec 1:\n",
      "NORM performance: (0.688, 0.5781, 0.6283)\n",
      "\n",
      "Exec 2:\n",
      "NORM performance: (0.6901, 0.576, 0.6279)\n",
      "\n",
      "Exec 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORM performance: (0.69, 0.5679, 0.623)\n",
      "\n",
      "Exec 4:\n",
      "NORM performance: (0.7036, 0.5764, 0.6337)\n",
      "\n",
      "Exec 5:\n",
      "NORM performance: (0.6903, 0.5693, 0.624)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "m_name = \"mbert_galen\"\n",
    "execs = [1, 2, 3, 4, 5]\n",
    "\n",
    "check_ner_norm_performance(model_name=m_name, arr_execs=execs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_avg</th>\n",
       "      <th>P_std</th>\n",
       "      <th>P_max</th>\n",
       "      <th>R_avg</th>\n",
       "      <th>R_std</th>\n",
       "      <th>R_max</th>\n",
       "      <th>F1_avg</th>\n",
       "      <th>F1_std</th>\n",
       "      <th>F1_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>0.694</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>0.684</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>0.694</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>0.692</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>0.678</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>0.686</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             P_avg  P_std  P_max  R_avg  R_std  R_max  F1_avg  F1_std  F1_max\n",
       "beto         0.694  0.005  0.702  0.559  0.005  0.565   0.619   0.001   0.622\n",
       "beto_galen   0.684  0.009  0.695  0.576  0.004  0.578   0.625   0.004   0.631\n",
       "mbert        0.694  0.007  0.703  0.564  0.003  0.568   0.622   0.003   0.627\n",
       "mbert_galen  0.692  0.006  0.704  0.574  0.005  0.578   0.627   0.004   0.634\n",
       "xlmr         0.678  0.012  0.691  0.564  0.003  0.568   0.616   0.004   0.622\n",
       "xlmr_galen   0.686  0.010  0.695  0.575  0.004  0.582   0.626   0.004   0.629"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance(\n",
    "    {\n",
    "        'beto': [1, 2, 3, 4, 5], \n",
    "        'beto_galen': [1, 2, 3, 4, 5],\n",
    "        'mbert': [1, 2, 3, 4, 5], \n",
    "        'mbert_galen': [1, 2, 3, 4, 5],\n",
    "        'xlmr': [1, 2, 3, 4, 5], \n",
    "        'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_avg_std</th>\n",
       "      <th>P_max</th>\n",
       "      <th>R_avg_std</th>\n",
       "      <th>R_max</th>\n",
       "      <th>F1_avg_std</th>\n",
       "      <th>F1_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>.694 Â± .005</td>\n",
       "      <td>.702</td>\n",
       "      <td>.559 Â± .005</td>\n",
       "      <td>.565</td>\n",
       "      <td>.619 Â± .001</td>\n",
       "      <td>.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>.684 Â± .009</td>\n",
       "      <td>.695</td>\n",
       "      <td>.576 Â± .004</td>\n",
       "      <td>.578</td>\n",
       "      <td>.625 Â± .004</td>\n",
       "      <td>.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>.694 Â± .007</td>\n",
       "      <td>.703</td>\n",
       "      <td>.564 Â± .003</td>\n",
       "      <td>.568</td>\n",
       "      <td>.622 Â± .003</td>\n",
       "      <td>.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>.692 Â± .006</td>\n",
       "      <td>.704</td>\n",
       "      <td>.574 Â± .005</td>\n",
       "      <td>.578</td>\n",
       "      <td>.627 Â± .004</td>\n",
       "      <td>.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>.678 Â± .012</td>\n",
       "      <td>.691</td>\n",
       "      <td>.564 Â± .003</td>\n",
       "      <td>.568</td>\n",
       "      <td>.616 Â± .004</td>\n",
       "      <td>.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>.686 Â± .01</td>\n",
       "      <td>.695</td>\n",
       "      <td>.575 Â± .004</td>\n",
       "      <td>.582</td>\n",
       "      <td>.626 Â± .004</td>\n",
       "      <td>.629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P_avg_std P_max    R_avg_std R_max   F1_avg_std F1_max\n",
       "beto         .694 Â± .005  .702  .559 Â± .005  .565  .619 Â± .001   .622\n",
       "beto_galen   .684 Â± .009  .695  .576 Â± .004  .578  .625 Â± .004   .631\n",
       "mbert        .694 Â± .007  .703  .564 Â± .003  .568  .622 Â± .003   .627\n",
       "mbert_galen  .692 Â± .006  .704  .574 Â± .005  .578  .627 Â± .004   .634\n",
       "xlmr         .678 Â± .012  .691  .564 Â± .003  .568  .616 Â± .004   .622\n",
       "xlmr_galen    .686 Â± .01  .695  .575 Â± .004  .582  .626 Â± .004   .629"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_df_paper(\n",
    "    model_performance(\n",
    "        {\n",
    "            'beto': [1, 2, 3, 4, 5], \n",
    "            'beto_galen': [1, 2, 3, 4, 5],\n",
    "            'mbert': [1, 2, 3, 4, 5], \n",
    "            'mbert_galen': [1, 2, 3, 4, 5],\n",
    "            'xlmr': [1, 2, 3, 4, 5], \n",
    "            'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the (F1) performance of all executions of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_f1_values(dict_names_execs, df_gs=df_test_gs):\n",
    "    \"\"\"\n",
    "    Generate a vector containing the F1 performance of all executions of all models, in the given order.\n",
    "    \n",
    "    dict_names_execs: each key is a string with the model name, and \n",
    "                      each value is a list with the random execs of the corresponding model.\n",
    "    \"\"\"\n",
    "    arr_values = []\n",
    "    for model_name in dict_names_execs:\n",
    "        for i_exec in dict_names_execs[model_name]:\n",
    "            df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                    str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "            _, _, f1 = calculate_codiesp_x_metrics(\n",
    "                df_gs=df_gs[df_gs['label_gs'] == TYPE_ANN], \n",
    "                df_pred=format_codiesp_x_pred_df(\n",
    "                    df_run=df_test_preds,\n",
    "                    valid_codes=valid_codes\n",
    "                )\n",
    "            )\n",
    "            arr_values.append(f1)\n",
    "    return arr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "arr_val = model_f1_values(\n",
    "    {\n",
    "        'beto': [1, 2, 3, 4, 5], \n",
    "        'beto_galen': [1, 2, 3, 4, 5],\n",
    "        'mbert': [1, 2, 3, 4, 5], \n",
    "        'mbert_galen': [1, 2, 3, 4, 5],\n",
    "        'xlmr': [1, 2, 3, 4, 5], \n",
    "        'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(arr_val).to_csv(RES_DIR + \"norm_f1_exec_\" + TYPE_TASK + \"_hier_task.csv\", index=False, header=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_corpus_path = \"../datasets/CodiEsp-SSplit-text/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = corpus_path + \"train/text_files/\"\n",
    "train_files = [f for f in os.listdir(train_path) if os.path.isfile(train_path + f) and f.split('.')[-1] == \"txt\"]\n",
    "train_data = load_text_files(train_files, train_path)\n",
    "df_text_train = pd.DataFrame({'doc_id': [s.split('.txt')[0] for s in train_files], 'raw_text': train_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_path = corpus_path + \"dev/text_files/\"\n",
    "dev_files = [f for f in os.listdir(dev_path) if os.path.isfile(dev_path + f) and f.split('.')[-1] == \"txt\"]\n",
    "dev_data = load_text_files(dev_files, dev_path)\n",
    "df_text_dev = pd.DataFrame({'doc_id': [s.split('.txt')[0] for s in dev_files], 'raw_text': dev_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = corpus_path + \"test/text_files/\"\n",
    "test_files = [f for f in os.listdir(test_path) if os.path.isfile(test_path + f) and f.split('.')[-1] == 'txt']\n",
    "test_data = load_text_files(test_files, test_path)\n",
    "df_text_test = pd.DataFrame({'doc_id': [s.split('.txt')[0] for s in test_files], 'raw_text': test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner = pd.read_table(corpus_path + \"train/trainX.tsv\", sep='\\t', header=None)\n",
    "df_codes_train_ner.columns = [\"doc_id\", \"type\", \"code\", \"word\", \"location\"]\n",
    "df_codes_train_ner = df_codes_train_ner[~df_codes_train_ner[['doc_id', 'type', 'location']].duplicated(keep='first')]\n",
    "df_codes_train_ner['disc'] = df_codes_train_ner['location'].apply(lambda x: ';' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one type of annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner = df_codes_train_ner[df_codes_train_ner['type'] == TYPE_ANN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final = process_labels_norm_prueba(df_ann=df_codes_train_ner[[\"doc_id\", \"type\", \"code\", \"word\", \"location\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove annotations of zero length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final['length'] = df_codes_train_ner_final.apply(lambda x: x['end'] - x['start'], axis=1)\n",
    "df_codes_train_ner_final = df_codes_train_ner_final[df_codes_train_ner_final['length'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate continuous and discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continiuous\n",
    "df_codes_train_ner_final_cont = df_codes_train_ner_final[df_codes_train_ner_final['disc'] == 0].copy()\n",
    "df_codes_train_ner_final_cont['disc'] = df_codes_train_ner_final_cont['disc'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discontinuous\n",
    "df_codes_train_ner_final_disc = restore_disc_ann(df_ann=df_codes_train_ner[df_codes_train_ner['disc']], \n",
    "                    df_ann_final=df_codes_train_ner_final[df_codes_train_ner_final['disc'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final_disc['start'] = df_codes_train_ner_final_disc['location'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df_codes_train_ner_final_disc['end'] = df_codes_train_ner_final_disc['location'].apply(lambda x: int(x.split(' ')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate continuous and discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat\n",
    "cols_concat = ['doc_id', 'type', 'code', 'word', 'location', 'start', 'end', 'disc']\n",
    "df_codes_train_ner_final = pd.concat([df_codes_train_ner_final_cont[cols_concat], \n",
    "                                      df_codes_train_ner_final_disc[cols_concat]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we remove the right-to-left (text wise) discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final['direction'] = df_codes_train_ner_final.apply(check_ann_left_right_direction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final = df_codes_train_ner_final[df_codes_train_ner_final['direction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only select the annotations fully contained in a single sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence-Split data\n",
    "ss_sub_corpus_path = ss_corpus_path + \"train/\"\n",
    "ss_files = [f for f in os.listdir(ss_sub_corpus_path) if os.path.isfile(ss_sub_corpus_path + f)]\n",
    "ss_dict_train = load_ss_files(ss_files, ss_sub_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mult_sent_train, df_one_sent_train, df_no_sent_train = check_ann_span_sent(df_ann=df_codes_train_ner_final, \n",
    "                                                                             ss_dict=ss_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final = df_one_sent_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    6134\n",
      "True      723\n",
      "Name: disc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_codes_train_ner_final.disc.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final.sort_values(['doc_id', 'start', 'end'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPE_TASK == 'd':\n",
    "    df_codes_train_ner_final[\"code_pre\"] = df_codes_train_ner_final[\"code\"].apply(lambda x: x.split('.')[0])\n",
    "    df_codes_train_ner_final[\"code_suf\"] = df_codes_train_ner_final[\"code\"].apply(lambda x: None if not '.' in x else x.split('.')[1])\n",
    "else:\n",
    "    df_codes_train_ner_final[\"code_pre\"] = df_codes_train_ner_final[\"code\"].apply(lambda x: x[:4])\n",
    "    df_codes_train_ner_final[\"code_suf\"] = df_codes_train_ner_final[\"code\"].apply(lambda x: None if len(x) < 7 else x[4:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner = pd.read_table(corpus_path + \"dev/devX.tsv\", sep='\\t', header=None)\n",
    "df_codes_dev_ner.columns = [\"doc_id\", \"type\", \"code\", \"word\", \"location\"]\n",
    "df_codes_dev_ner = df_codes_dev_ner[~df_codes_dev_ner[['doc_id', 'type', 'location']].duplicated(keep='first')]\n",
    "df_codes_dev_ner['disc'] = df_codes_dev_ner['location'].apply(lambda x: ';' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one type of annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner = df_codes_dev_ner[df_codes_dev_ner['type'] == TYPE_ANN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final = process_labels_norm_prueba(df_ann=df_codes_dev_ner[[\"doc_id\", \"type\", \"code\", \"word\", \"location\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove annotations of zero length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final['length'] = df_codes_dev_ner_final.apply(lambda x: x['end'] - x['start'], axis=1)\n",
    "df_codes_dev_ner_final = df_codes_dev_ner_final[df_codes_dev_ner_final['length'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate continuous and discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continiuous\n",
    "df_codes_dev_ner_final_cont = df_codes_dev_ner_final[df_codes_dev_ner_final['disc'] == 0].copy()\n",
    "df_codes_dev_ner_final_cont['disc'] = df_codes_dev_ner_final_cont['disc'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discontinuous\n",
    "df_codes_dev_ner_final_disc = restore_disc_ann(df_ann=df_codes_dev_ner[df_codes_dev_ner['disc']], \n",
    "                    df_ann_final=df_codes_dev_ner_final[df_codes_dev_ner_final['disc'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final_disc['start'] = df_codes_dev_ner_final_disc['location'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df_codes_dev_ner_final_disc['end'] = df_codes_dev_ner_final_disc['location'].apply(lambda x: int(x.split(' ')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate continuous and discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat\n",
    "cols_concat = ['doc_id', 'type', 'code', 'word', 'location', 'start', 'end', 'disc']\n",
    "df_codes_dev_ner_final = pd.concat([df_codes_dev_ner_final_cont[cols_concat], \n",
    "                                      df_codes_dev_ner_final_disc[cols_concat]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we remove the right-to-left (text wise) discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final['direction'] = df_codes_dev_ner_final.apply(check_ann_left_right_direction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final = df_codes_dev_ner_final[df_codes_dev_ner_final['direction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only select the annotations fully contained in a single sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence-Split data\n",
    "ss_sub_corpus_path = ss_corpus_path + \"dev/\"\n",
    "ss_files = [f for f in os.listdir(ss_sub_corpus_path) if os.path.isfile(ss_sub_corpus_path + f)]\n",
    "ss_dict_dev = load_ss_files(ss_files, ss_sub_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mult_sent_dev, df_one_sent_dev, df_no_sent_dev = check_ann_span_sent(df_ann=df_codes_dev_ner_final, \n",
    "                                                                             ss_dict=ss_dict_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final = df_one_sent_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    2910\n",
      "True      362\n",
      "Name: disc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_codes_dev_ner_final.disc.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final.sort_values(['doc_id', 'start', 'end'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPE_TASK == 'd':\n",
    "    df_codes_dev_ner_final[\"code_pre\"] = df_codes_dev_ner_final[\"code\"].apply(lambda x: x.split('.')[0])\n",
    "    df_codes_dev_ner_final[\"code_suf\"] = df_codes_dev_ner_final[\"code\"].apply(lambda x: None if not '.' in x else x.split('.')[1])\n",
    "else:\n",
    "    df_codes_dev_ner_final[\"code_pre\"] = df_codes_dev_ner_final[\"code\"].apply(lambda x: x[:4])\n",
    "    df_codes_dev_ner_final[\"code_suf\"] = df_codes_dev_ner_final[\"code\"].apply(lambda x: None if len(x) < 7 else x[4:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_codes_pre = sorted(set(df_codes_dev_ner_final[\"code_pre\"].values).union(set(\n",
    "    df_codes_train_ner_final[\"code_pre\"].values\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "901"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dev_codes_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_codes_suf = sorted(set(df_codes_dev_ner_final[df_codes_dev_ner_final['code_suf'].apply(lambda x: x is not None)][\"code_suf\"].values).union(set(df_codes_train_ner_final[df_codes_train_ner_final['code_suf'].apply(lambda x: x is not None)][\"code_suf\"].values))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dev_codes_suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IOB-2 and Clinical-Coding label encoders as dict (more computationally efficient)\n",
    "iob_lab_encoder = {\"B\": 0, \"I\": 1, \"O\": 2}\n",
    "iob_lab_decoder = {0: \"B\", 1: \"I\", 2: \"O\"}\n",
    "\n",
    "# Code-pre\n",
    "code_pre_lab_encoder = {}\n",
    "code_pre_lab_decoder = {}\n",
    "i = 0\n",
    "for code in train_dev_codes_pre:\n",
    "    code_pre_lab_encoder[code] = i\n",
    "    code_pre_lab_decoder[i] = code\n",
    "    i += 1\n",
    "    \n",
    "code_pre_lab_encoder[\"O\"] = i\n",
    "code_pre_lab_decoder[i] = \"O\"\n",
    "\n",
    "# Code-suf\n",
    "code_suf_lab_encoder = {}\n",
    "code_suf_lab_decoder = {}\n",
    "i = 0\n",
    "for code in train_dev_codes_suf:\n",
    "    code_suf_lab_encoder[code] = i\n",
    "    code_suf_lab_decoder[i] = code\n",
    "    i += 1\n",
    "\n",
    "# Add \"O\" label to code-suf, since some codes do not have suffix\n",
    "code_suf_lab_encoder[\"O\"] = i\n",
    "code_suf_lab_decoder[i] = \"O\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n"
     ]
    }
   ],
   "source": [
    "print(len(iob_lab_encoder), len(iob_lab_decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 902\n"
     ]
    }
   ],
   "source": [
    "print(len(code_pre_lab_encoder), len(code_pre_lab_decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306 306\n"
     ]
    }
   ],
   "source": [
    "print(len(code_suf_lab_encoder), len(code_suf_lab_decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_EVAL_STRAT = 'sum'\n",
    "RES_DIR_ENS = RES_DIR + \"ensemble/\"\n",
    "\n",
    "subtask = 'norm'\n",
    "subtask_ann = subtask + '-iob_code_suf'\n",
    "\n",
    "CODE_SEP = '.' if TYPE_ANN == 'DIAGNOSTICO' else ''\n",
    "\n",
    "arr_exec = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ens_performance(ens_name, ner_model_name, arr_model_name, \n",
    "                    res_dir=RES_DIR_ENS, prefix_name='', arr_exec=arr_exec, \n",
    "                    df_gs=df_test_gs, \n",
    "                    code_pre_lab_decoder=code_pre_lab_decoder, \n",
    "                    code_suf_lab_decoder=code_suf_lab_decoder, \n",
    "                    ens_eval_strategy=ENS_EVAL_STRAT, \n",
    "                    subtask_ann=subtask_ann):\n",
    "    df_ens_ner = pd.read_csv(res_dir + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             ner_model_name + \"_ann.csv\", header=0, sep='\\t')\n",
    "    ens_preds_code_pre, ens_preds_code_suf = [], []\n",
    "    for model_name in arr_model_name:\n",
    "        for i_exec in arr_exec:\n",
    "            ens_preds_code_pre.append(np.load(file=res_dir + prefix_name + \"test_preds_code_pre_ens_ner_\" + ens_name + \\\n",
    "                                              \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\"))\n",
    "            ens_preds_code_suf.append(np.load(file=res_dir + prefix_name + \"test_preds_code_suf_ens_ner_\" + ens_name + \\\n",
    "                                              \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\"))\n",
    "\n",
    "    # Sanity check: all preds array have the same shape\n",
    "    assert len(ens_preds_code_pre) == len(ens_preds_code_suf)\n",
    "    for i in range(len(ens_preds_code_pre) - 1):\n",
    "        assert ens_preds_code_pre[i].shape == ens_preds_code_pre[i + 1].shape\n",
    "        assert ens_preds_code_suf[i].shape == ens_preds_code_suf[i + 1].shape\n",
    "    \n",
    "    print(\"NÂº executions:\", len(ens_preds_code_pre))\n",
    "\n",
    "    if ens_eval_strategy == 'sum':\n",
    "        ens_code_pre = np.sum(ens_preds_code_pre, axis=0)\n",
    "        ens_code_suf = np.sum(ens_preds_code_suf, axis=0)\n",
    "    else: # default 'prod'\n",
    "        ens_code_pre = np.prod(ens_preds_code_pre, axis=0)\n",
    "        ens_code_suf = np.prod(ens_preds_code_suf, axis=0)\n",
    "\n",
    "    df_ens_preds = cls_code_norm_preds_brat_format(\n",
    "        y_pred_cls=[ens_code_pre, ens_code_suf], \n",
    "        df_pred_ner=df_ens_ner, \n",
    "        code_decoder_list=[code_pre_lab_decoder, code_suf_lab_decoder],\n",
    "        subtask=subtask_ann,\n",
    "        code_sep=CODE_SEP,\n",
    "        codes_pre_o_mask=None,\n",
    "        codes_pre_suf_mask=None\n",
    "    )\n",
    "    \n",
    "    # Adapt to CodiEsp format\n",
    "    df_ens_preds['label_pred'] = TYPE_ANN\n",
    "    df_ens_preds['pos_pred'] = [str(row['start']) + ' ' + str(row['end']) for index, row in df_ens_preds.iterrows()]\n",
    "    df_ens_preds = df_ens_preds.rename(columns={'code_pred': 'code'})\n",
    "    df_ens_preds = df_ens_preds[['clinical_case', 'pos_pred', 'label_pred', 'code']]\n",
    "\n",
    "    return df_ens_preds, calculate_codiesp_x_metrics(\n",
    "        df_gs=df_gs[df_gs['label_gs'] == TYPE_ANN], \n",
    "        df_pred=format_codiesp_x_pred_df(\n",
    "            df_run=df_ens_preds,\n",
    "            valid_codes=valid_codes\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'beto'\n",
    "ner_model_name = ens_name\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº executions: 5\n",
      "(0.7185, 0.5711, 0.6363)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BETO-GalÃ©n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'beto_galen'\n",
    "ner_model_name = 'beto_galen'\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº executions: 5\n",
      "(0.7051, 0.5848, 0.6394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'mbert'\n",
    "ner_model_name = 'mbert'\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº executions: 5\n",
      "(0.7219, 0.5735, 0.6392)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mBERT-GalÃ©n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'mbert_galen'\n",
    "ner_model_name = 'mbert_galen'\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº executions: 5\n",
      "(0.7136, 0.5795, 0.6396)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'xlmr'\n",
    "ner_model_name = 'xlmr'\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº executions: 5\n",
      "(0.7031, 0.5742, 0.6322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM-R-GalÃ©n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'xlmr_galen'\n",
    "ner_model_name = 'xlmr_galen'\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº executions: 5\n",
      "(0.7047, 0.5862, 0.64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BETO + BETO-GalÃ©n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model_name = ['beto', 'beto_galen']\n",
    "ens_name = '_'.join(arr_model_name)\n",
    "ner_model_name = 'beto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº executions: 10\n",
      "(0.7212, 0.5844, 0.6457)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mBERT + mBERT-GalÃ©n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model_name = ['mbert', 'mbert_galen']\n",
    "ens_name = '_'.join(arr_model_name)\n",
    "ner_model_name = 'mbert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº executions: 10\n",
      "(0.7276, 0.5788, 0.6447)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM-R + XLM-R-GalÃ©n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model_name = ['xlmr', 'xlmr_galen']\n",
    "ens_name = '_'.join(arr_model_name)\n",
    "ner_model_name = 'xlmr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº executions: 10\n",
      "(0.7231, 0.5862, 0.6475)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_ENS_PREF = \"multi_model_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_empty_ner_preds(ens_name, ner_model_name, arr_model_name, \n",
    "                        res_dir=RES_DIR_ENS, empty_value=0, \n",
    "                        prefix_name=MULTI_ENS_PREF):\n",
    "    \"\"\"\n",
    "    Considering a set of NER predictions as reference, this procedure inserts empty code-pre and code-suf\n",
    "    samples in the case a certain model does not predict a reference NER sample.\n",
    "    \"\"\"\n",
    "    # Load reference DF of NER predictions\n",
    "    df_ref_ens_ner = pd.read_csv(res_dir + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                                 ner_model_name + \"_ann.csv\", header=0, sep='\\t')\n",
    "    for model_name in arr_model_name:\n",
    "        # Load DF of NER predictions from the current model\n",
    "        df_ens_ner = pd.read_csv(res_dir + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                                 model_name + \"_ann.csv\", header=0, sep='\\t')\n",
    "        assert df_ens_ner.shape[0] <= df_ref_ens_ner.shape[0]\n",
    "        arr_i_insert = []\n",
    "        if df_ens_ner.shape[0] < df_ref_ens_ner.shape[0]:\n",
    "            # Check the indices of the absent samples, i.e. reference NER samples that are not predicted by the current model\n",
    "            absent_samples = set(df_ref_ens_ner.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), \n",
    "                                                      axis=1)) - \\\n",
    "                             set(df_ens_ner.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), \n",
    "                                                  axis=1))\n",
    "            assert len(absent_samples) == df_ref_ens_ner.shape[0] - df_ens_ner.shape[0]\n",
    "            arr_i_absent = []\n",
    "            for s in absent_samples:\n",
    "                s = s.split('|')\n",
    "                s_index = df_ref_ens_ner[(df_ref_ens_ner['clinical_case'] == s[0]) & (df_ref_ens_ner['location'] == s[1])].index[0]\n",
    "                arr_i_absent.append(np.where(df_ref_ens_ner.index.values == s_index)[0][0])\n",
    "            assert len(arr_i_absent) > 0\n",
    "            # Sort indices of absent samples\n",
    "            arr_i_absent = np.sort(arr_i_absent)\n",
    "            # Convert indices of absent samples to insertion indices\n",
    "            arr_i_insert.append(arr_i_absent[0])\n",
    "            for i in range(1, len(arr_i_absent)):\n",
    "                arr_i_insert.append(arr_i_absent[i] - i) # needs to be sanity checked\n",
    "        ## Insert empty values for the absent samples (if any)\n",
    "        for i_exec in arr_exec:\n",
    "            # Load predictions of both code prefix and suffix\n",
    "            preds_code_pre = np.load(file=res_dir + \"test_preds_code_pre_ens_ner_\" + ens_name + \\\n",
    "                                     \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\")\n",
    "            preds_code_suf = np.load(file=res_dir + \"test_preds_code_suf_ens_ner_\" + ens_name + \\\n",
    "                                     \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\")\n",
    "            preds_code_pre = np.insert(arr=preds_code_pre, obj=arr_i_insert, values=empty_value, axis=0)\n",
    "            preds_code_suf = np.insert(arr=preds_code_suf, obj=arr_i_insert, values=empty_value, axis=0)\n",
    "            # Save predictions after insertion\n",
    "            np.save(file=res_dir + prefix_name + \"test_preds_code_pre_ens_ner_\" + ens_name + \\\n",
    "                    \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\",\n",
    "                    arr=preds_code_pre)\n",
    "            np.save(file=res_dir + prefix_name + \"test_preds_code_suf_ens_ner_\" + ens_name + \\\n",
    "                    \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\",\n",
    "                    arr=preds_code_suf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BETO + mBERT + XLM-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = \"beto_mbert_xlmr\"\n",
    "arr_model_name = ['beto', 'mbert', 'xlmr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_iob = pd.read_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_iob_\" + ens_name + \".csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2869, 5)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_iob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_beto = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[0] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2867, 5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_beto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_beto = set(df_ens_ner_beto.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2861"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_beto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_mbert = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[1] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2867, 5)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_mbert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_mbert = set(df_ens_ner_mbert.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2861"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_mbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_xlmr = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[2] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2866, 5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_xlmr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_xlmr = set(df_ens_ner_xlmr.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2860"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_xlmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set_ens_ner_beto == set_ens_ner_mbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_xlmr - set_ens_ner_beto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_beto - set_ens_ner_xlmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both BETO and mBERT models could be empoyed as NER-reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model_name = \"beto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_empty_ner_preds(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name, \n",
    "    empty_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº executions: 15\n",
      "(0.7332, 0.5802, 0.6478)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name,\n",
    "    prefix_name=MULTI_ENS_PREF\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BETO-GalÃ©n + mBERT-GalÃ©n + XLM-R-GalÃ©n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = \"beto_galen_mbert_galen_xlmr_galen\"\n",
    "arr_model_name = ['beto_galen', 'mbert_galen', 'xlmr_galen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_iob = pd.read_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_iob_\" + ens_name + \".csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2957, 5)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_iob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_beto = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[0] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2951, 5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_beto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_beto = set(df_ens_ner_beto.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2948"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_beto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_mbert = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[1] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2951, 5)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_mbert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_mbert = set(df_ens_ner_mbert.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2948"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_mbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_xlmr = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[2] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2950, 5)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_xlmr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_xlmr = set(df_ens_ner_xlmr.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2947"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_xlmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set_ens_ner_beto == set_ens_ner_mbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_xlmr - set_ens_ner_beto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_beto - set_ens_ner_xlmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both BETO-GalÃ©n and mBERT-GalÃ©n models could be empoyed as NER-reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model_name = \"beto_galen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_empty_ner_preds(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name, \n",
    "    empty_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÂº executions: 15\n",
      "(0.7277, 0.5932, 0.6536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name,\n",
    "    prefix_name=MULTI_ENS_PREF\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dic_ens_res, index=[\"P\", \"R\", \"F1\"]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>0.7185</td>\n",
       "      <td>0.5711</td>\n",
       "      <td>0.6363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>0.7051</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>0.6394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>0.7219</td>\n",
       "      <td>0.5735</td>\n",
       "      <td>0.6392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>0.7136</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.6396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>0.7031</td>\n",
       "      <td>0.5742</td>\n",
       "      <td>0.6322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>0.7047</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_beto_galen</th>\n",
       "      <td>0.7212</td>\n",
       "      <td>0.5844</td>\n",
       "      <td>0.6457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_mbert_galen</th>\n",
       "      <td>0.7276</td>\n",
       "      <td>0.5788</td>\n",
       "      <td>0.6447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_xlmr_galen</th>\n",
       "      <td>0.7231</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.6475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_mbert_xlmr</th>\n",
       "      <td>0.7332</td>\n",
       "      <td>0.5802</td>\n",
       "      <td>0.6478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen_mbert_galen_xlmr_galen</th>\n",
       "      <td>0.7277</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.6536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        P       R      F1\n",
       "beto                               0.7185  0.5711  0.6363\n",
       "beto_galen                         0.7051  0.5848  0.6394\n",
       "mbert                              0.7219  0.5735  0.6392\n",
       "mbert_galen                        0.7136  0.5795  0.6396\n",
       "xlmr                               0.7031  0.5742  0.6322\n",
       "xlmr_galen                         0.7047  0.5862  0.6400\n",
       "beto_beto_galen                    0.7212  0.5844  0.6457\n",
       "mbert_mbert_galen                  0.7276  0.5788  0.6447\n",
       "xlmr_xlmr_galen                    0.7231  0.5862  0.6475\n",
       "beto_mbert_xlmr                    0.7332  0.5802  0.6478\n",
       "beto_galen_mbert_galen_xlmr_galen  0.7277  0.5932  0.6536"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df = format_df_paper(\n",
    "    model_performance(\n",
    "        {\n",
    "            'beto': [1, 2, 3, 4, 5], \n",
    "            'beto_galen': [1, 2, 3, 4, 5],\n",
    "            'mbert': [1, 2, 3, 4, 5], \n",
    "            'mbert_galen': [1, 2, 3, 4, 5],\n",
    "            'xlmr': [1, 2, 3, 4, 5], \n",
    "            'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "        },\n",
    "        multi_task=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_avg_std</th>\n",
       "      <th>P_max</th>\n",
       "      <th>R_avg_std</th>\n",
       "      <th>R_max</th>\n",
       "      <th>F1_avg_std</th>\n",
       "      <th>F1_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>.71 Â± .019</td>\n",
       "      <td>.736</td>\n",
       "      <td>.544 Â± .01</td>\n",
       "      <td>.553</td>\n",
       "      <td>.616 Â± .005</td>\n",
       "      <td>.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>.703 Â± .019</td>\n",
       "      <td>.735</td>\n",
       "      <td>.561 Â± .002</td>\n",
       "      <td>.563</td>\n",
       "      <td>.624 Â± .008</td>\n",
       "      <td>.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>.688 Â± .017</td>\n",
       "      <td>.703</td>\n",
       "      <td>.559 Â± .007</td>\n",
       "      <td>.564</td>\n",
       "      <td>.617 Â± .006</td>\n",
       "      <td>.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>.701 Â± .005</td>\n",
       "      <td>.707</td>\n",
       "      <td>.566 Â± .004</td>\n",
       "      <td>.572</td>\n",
       "      <td>.627 Â± .003</td>\n",
       "      <td>.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>.667 Â± .015</td>\n",
       "      <td>.688</td>\n",
       "      <td>.564 Â± .003</td>\n",
       "      <td>.569</td>\n",
       "      <td>.611 Â± .007</td>\n",
       "      <td>.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>.694 Â± .009</td>\n",
       "      <td>.704</td>\n",
       "      <td>.565 Â± .004</td>\n",
       "      <td>.569</td>\n",
       "      <td>.623 Â± .006</td>\n",
       "      <td>.628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P_avg_std P_max    R_avg_std R_max   F1_avg_std F1_max\n",
       "beto          .71 Â± .019  .736   .544 Â± .01  .553  .616 Â± .005   .623\n",
       "beto_galen   .703 Â± .019  .735  .561 Â± .002  .563  .624 Â± .008   .637\n",
       "mbert        .688 Â± .017  .703  .559 Â± .007  .564  .617 Â± .006   .621\n",
       "mbert_galen  .701 Â± .005  .707  .566 Â± .004  .572  .627 Â± .003    .63\n",
       "xlmr         .667 Â± .015  .688  .564 Â± .003  .569  .611 Â± .007    .62\n",
       "xlmr_galen   .694 Â± .009  .704  .565 Â± .004  .569  .623 Â± .006   .628"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the (F1) performance of all executions of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_model_f1_values(dict_names_execs, df_gs=df_test_gs):\n",
    "    \"\"\"\n",
    "    Generate a vector containing the F1 performance of all executions of all models, in the given order.\n",
    "    \n",
    "    dict_names_execs: each key is a string with the model name, and \n",
    "                      each value is a list with the random execs of the corresponding model.\n",
    "    \"\"\"\n",
    "    arr_values = []\n",
    "    for model_name in dict_names_execs:\n",
    "        for i_exec in dict_names_execs[model_name]:\n",
    "            df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_multi_task_ner_\" + str(i_exec) + \"_\" + TYPE_TASK + \\\n",
    "                    \"_hier_task_cls_\" + str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "            _, _, f1 = calculate_codiesp_x_metrics(\n",
    "                df_gs=df_gs[df_gs['label_gs'] == TYPE_ANN], \n",
    "                df_pred=format_codiesp_x_pred_df(\n",
    "                    df_run=df_test_preds,\n",
    "                    valid_codes=valid_codes\n",
    "                )\n",
    "            )\n",
    "            arr_values.append(f1)\n",
    "    return arr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "arr_val = multi_model_f1_values(\n",
    "    {\n",
    "        'beto': [1, 2, 3, 4, 5], \n",
    "        'beto_galen': [1, 2, 3, 4, 5],\n",
    "        'mbert': [1, 2, 3, 4, 5], \n",
    "        'mbert_galen': [1, 2, 3, 4, 5],\n",
    "        'xlmr': [1, 2, 3, 4, 5], \n",
    "        'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(arr_val).to_csv(RES_DIR + \"norm_f1_exec_\" + TYPE_TASK + \"_multi_task_ner_hier_task.csv\", index=False, header=False, sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
