{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_path = \"../utils/\"\n",
    "corpus_path = \"../datasets/final_dataset_v4_to_publish/\"\n",
    "test_gs_path = corpus_path + \"test/testX.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 08:38:32.733082: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4812: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Auxiliary components\n",
    "import sys\n",
    "sys.path.insert(0, utils_path)\n",
    "from nlp_utils import *\n",
    "\n",
    "RES_DIR = \"../results/CodiEsp/final_exec/\"\n",
    "\n",
    "TYPE_ANN = \"PROCEDIMIENTO\"\n",
    "TYPE_TASK = TYPE_ANN[0].lower()\n",
    "\n",
    "# GS data\n",
    "df_test_gs = format_codiesp_x_gs(test_gs_path)\n",
    "\n",
    "codes_d_path = corpus_path + \"codiesp_codes/codiesp-\" + TYPE_TASK.upper() + \"_codes.tsv\"\n",
    "valid_codes = set(pd.read_csv(codes_d_path, sep='\\t', header=None, \n",
    "                                  usecols=[0])[0].tolist())\n",
    "valid_codes = set([x.lower() for x in valid_codes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ner_norm_performance(model_name, arr_execs):\n",
    "    \"\"\"\n",
    "    Sanity-check procedure that prints the NORM performance of each single model execution.\n",
    "    \"\"\"\n",
    "    for i_exec in arr_execs:\n",
    "        print(\"Exec \" + str(i_exec) + \":\")\n",
    "        df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "        print(\"NORM performance:\", calculate_codiesp_x_metrics(\n",
    "            df_gs=df_test_gs[df_test_gs['label_gs'] == TYPE_ANN], \n",
    "            df_pred=format_codiesp_x_pred_df(\n",
    "                df_run=df_test_preds,\n",
    "                valid_codes=valid_codes\n",
    "            )\n",
    "        ), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(dict_names_execs, \n",
    "                      df_gs=df_test_gs,\n",
    "                      round_n=3, multi_task=False):\n",
    "    \"\"\"\n",
    "    Generate a pd.DataFrame with the statistics of the performance of each model.\n",
    "    \n",
    "    dict_names_execs: each key is a string with the model name, and \n",
    "                      each value is a list with the execs of the corresponding model.\n",
    "    \"\"\"\n",
    "    res_dict = {}\n",
    "    for model_name in dict_names_execs:\n",
    "        p_res, r_res, f1_res = [], [], []\n",
    "        for i_exec in dict_names_execs[model_name]:\n",
    "            if multi_task:\n",
    "                df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_multi_task_ner_\" + str(i_exec) + \"_\" + \\\n",
    "                    TYPE_TASK + \"_hier_task_cls_\" + str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "            else:\n",
    "                df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                    str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "            p, r, f1 = calculate_codiesp_x_metrics(\n",
    "                df_gs=df_gs[df_gs['label_gs'] == TYPE_ANN], \n",
    "                df_pred=format_codiesp_x_pred_df(\n",
    "                    df_run=df_test_preds,\n",
    "                    valid_codes=valid_codes\n",
    "                )\n",
    "            )\n",
    "            p_res.append(p)\n",
    "            r_res.append(r)\n",
    "            f1_res.append(f1)\n",
    "        p_res_stat = pd.Series(p_res).describe()\n",
    "        r_res_stat = pd.Series(r_res).describe()\n",
    "        f1_res_stat = pd.Series(f1_res).describe()\n",
    "        res_dict[model_name] = {\"P_avg\": round(p_res_stat['mean'], round_n), \"P_std\": round(p_res_stat['std'], round_n), \n",
    "                                \"P_max\": round(p_res_stat['max'], round_n),\n",
    "                                \"R_avg\": round(r_res_stat['mean'], round_n), \"R_std\": round(r_res_stat['std'], round_n), \n",
    "                                \"R_max\": round(r_res_stat['max'], round_n),\n",
    "                                \"F1_avg\": round(f1_res_stat['mean'], round_n), \"F1_std\": round(f1_res_stat['std'], round_n), \n",
    "                                \"F1_max\": round(f1_res_stat['max'], round_n)}\n",
    "    return pd.DataFrame(res_dict, index=[\"P_avg\", \"P_std\", \"P_max\", \n",
    "                                         \"R_avg\", \"R_std\", \"R_max\", \n",
    "                                         \"F1_avg\", \"F1_std\", \"F1_max\"]).transpose()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_paper(df_res):\n",
    "    arr_metrics = [\"P\", \"R\", \"F1\"]\n",
    "    arr_cols = []\n",
    "    for metric in arr_metrics:\n",
    "        df_res[metric + '_avg_std'] = df_res.apply(\n",
    "            lambda x: \".\" + str(x[metric + '_avg']).split('.')[-1] + \" ± \" + \\\n",
    "                \".\" + str(x[metric + '_std']).split('.')[-1], \n",
    "            axis=1\n",
    "        )\n",
    "        df_res[metric + '_max'] = df_res[metric + '_max'].apply(\n",
    "            lambda x: \".\" + str(x).split('.')[-1]\n",
    "        )\n",
    "        arr_cols += [metric + '_avg_std', metric + '_max']\n",
    "    return df_res[arr_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec 1:\n",
      "NORM performance: (0.592, 0.4539, 0.5138)\n",
      "\n",
      "Exec 2:\n",
      "NORM performance: (0.6201, 0.4346, 0.511)\n",
      "\n",
      "Exec 3:\n",
      "NORM performance: (0.6268, 0.4528, 0.5258)\n",
      "\n",
      "Exec 4:\n",
      "NORM performance: (0.6501, 0.4312, 0.5185)\n",
      "\n",
      "Exec 5:\n",
      "NORM performance: (0.6028, 0.4437, 0.5111)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "m_name = \"xlmr\"\n",
    "execs = [1, 2, 3, 4, 5]\n",
    "\n",
    "check_ner_norm_performance(model_name=m_name, arr_execs=execs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec 1:\n",
      "NORM performance: (0.6155, 0.4608, 0.527)\n",
      "\n",
      "Exec 2:\n",
      "NORM performance: (0.6328, 0.4608, 0.5332)\n",
      "\n",
      "Exec 3:\n",
      "NORM performance: (0.6375, 0.4482, 0.5264)\n",
      "\n",
      "Exec 4:\n",
      "NORM performance: (0.6446, 0.4767, 0.5481)\n",
      "\n",
      "Exec 5:\n",
      "NORM performance: (0.649, 0.446, 0.5287)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "m_name = \"beto_galen\"\n",
    "execs = [1, 2, 3, 4, 5]\n",
    "\n",
    "check_ner_norm_performance(model_name=m_name, arr_execs=execs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_avg</th>\n",
       "      <th>P_std</th>\n",
       "      <th>P_max</th>\n",
       "      <th>R_avg</th>\n",
       "      <th>R_std</th>\n",
       "      <th>R_max</th>\n",
       "      <th>F1_avg</th>\n",
       "      <th>F1_std</th>\n",
       "      <th>F1_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>0.635</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>0.636</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>0.639</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>0.647</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>0.618</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             P_avg  P_std  P_max  R_avg  R_std  R_max  F1_avg  F1_std  F1_max\n",
       "beto         0.635  0.024  0.661  0.442  0.007  0.449   0.521   0.009   0.535\n",
       "beto_galen   0.636  0.013  0.649  0.458  0.012  0.477   0.533   0.009   0.548\n",
       "mbert        0.639  0.023  0.665  0.441  0.008  0.452   0.522   0.007   0.533\n",
       "mbert_galen  0.647  0.014  0.661  0.467  0.004  0.471   0.542   0.005   0.548\n",
       "xlmr         0.618  0.022  0.650  0.443  0.010  0.454   0.516   0.006   0.526\n",
       "xlmr_galen   0.625  0.023  0.658  0.462  0.011  0.474   0.531   0.006   0.536"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance(\n",
    "    {\n",
    "        'beto': [1, 2, 3, 4, 5], \n",
    "        'beto_galen': [1, 2, 3, 4, 5],\n",
    "        'mbert': [1, 2, 3, 4, 5], \n",
    "        'mbert_galen': [1, 2, 3, 4, 5],\n",
    "        'xlmr': [1, 2, 3, 4, 5], \n",
    "        'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_avg_std</th>\n",
       "      <th>P_max</th>\n",
       "      <th>R_avg_std</th>\n",
       "      <th>R_max</th>\n",
       "      <th>F1_avg_std</th>\n",
       "      <th>F1_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>.635 ± .024</td>\n",
       "      <td>.661</td>\n",
       "      <td>.442 ± .007</td>\n",
       "      <td>.449</td>\n",
       "      <td>.521 ± .009</td>\n",
       "      <td>.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>.636 ± .013</td>\n",
       "      <td>.649</td>\n",
       "      <td>.458 ± .012</td>\n",
       "      <td>.477</td>\n",
       "      <td>.533 ± .009</td>\n",
       "      <td>.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>.639 ± .023</td>\n",
       "      <td>.665</td>\n",
       "      <td>.441 ± .008</td>\n",
       "      <td>.452</td>\n",
       "      <td>.522 ± .007</td>\n",
       "      <td>.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>.647 ± .014</td>\n",
       "      <td>.661</td>\n",
       "      <td>.467 ± .004</td>\n",
       "      <td>.471</td>\n",
       "      <td>.542 ± .005</td>\n",
       "      <td>.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>.618 ± .022</td>\n",
       "      <td>.65</td>\n",
       "      <td>.443 ± .01</td>\n",
       "      <td>.454</td>\n",
       "      <td>.516 ± .006</td>\n",
       "      <td>.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>.625 ± .023</td>\n",
       "      <td>.658</td>\n",
       "      <td>.462 ± .011</td>\n",
       "      <td>.474</td>\n",
       "      <td>.531 ± .006</td>\n",
       "      <td>.536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P_avg_std P_max    R_avg_std R_max   F1_avg_std F1_max\n",
       "beto         .635 ± .024  .661  .442 ± .007  .449  .521 ± .009   .535\n",
       "beto_galen   .636 ± .013  .649  .458 ± .012  .477  .533 ± .009   .548\n",
       "mbert        .639 ± .023  .665  .441 ± .008  .452  .522 ± .007   .533\n",
       "mbert_galen  .647 ± .014  .661  .467 ± .004  .471  .542 ± .005   .548\n",
       "xlmr         .618 ± .022   .65   .443 ± .01  .454  .516 ± .006   .526\n",
       "xlmr_galen   .625 ± .023  .658  .462 ± .011  .474  .531 ± .006   .536"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_df_paper(\n",
    "    model_performance(\n",
    "        {\n",
    "            'beto': [1, 2, 3, 4, 5], \n",
    "            'beto_galen': [1, 2, 3, 4, 5],\n",
    "            'mbert': [1, 2, 3, 4, 5], \n",
    "            'mbert_galen': [1, 2, 3, 4, 5],\n",
    "            'xlmr': [1, 2, 3, 4, 5], \n",
    "            'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the (F1) performance of all executions of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_f1_values(dict_names_execs, df_gs=df_test_gs):\n",
    "    \"\"\"\n",
    "    Generate a vector containing the F1 performance of all executions of all models, in the given order.\n",
    "    \n",
    "    dict_names_execs: each key is a string with the model name, and \n",
    "                      each value is a list with the random execs of the corresponding model.\n",
    "    \"\"\"\n",
    "    arr_values = []\n",
    "    for model_name in dict_names_execs:\n",
    "        for i_exec in dict_names_execs[model_name]:\n",
    "            df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                    str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "            _, _, f1 = calculate_codiesp_x_metrics(\n",
    "                df_gs=df_gs[df_gs['label_gs'] == TYPE_ANN], \n",
    "                df_pred=format_codiesp_x_pred_df(\n",
    "                    df_run=df_test_preds,\n",
    "                    valid_codes=valid_codes\n",
    "                )\n",
    "            )\n",
    "            arr_values.append(f1)\n",
    "    return arr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "arr_val = model_f1_values(\n",
    "    {\n",
    "        'beto': [1, 2, 3, 4, 5], \n",
    "        'beto_galen': [1, 2, 3, 4, 5],\n",
    "        'mbert': [1, 2, 3, 4, 5], \n",
    "        'mbert_galen': [1, 2, 3, 4, 5],\n",
    "        'xlmr': [1, 2, 3, 4, 5], \n",
    "        'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(arr_val).to_csv(RES_DIR + \"norm_f1_exec_\" + TYPE_TASK + \"_hier_task.csv\", index=False, header=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_corpus_path = \"../datasets/CodiEsp-SSplit-text/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = corpus_path + \"train/text_files/\"\n",
    "train_files = [f for f in os.listdir(train_path) if os.path.isfile(train_path + f) and f.split('.')[-1] == \"txt\"]\n",
    "train_data = load_text_files(train_files, train_path)\n",
    "df_text_train = pd.DataFrame({'doc_id': [s.split('.txt')[0] for s in train_files], 'raw_text': train_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_path = corpus_path + \"dev/text_files/\"\n",
    "dev_files = [f for f in os.listdir(dev_path) if os.path.isfile(dev_path + f) and f.split('.')[-1] == \"txt\"]\n",
    "dev_data = load_text_files(dev_files, dev_path)\n",
    "df_text_dev = pd.DataFrame({'doc_id': [s.split('.txt')[0] for s in dev_files], 'raw_text': dev_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = corpus_path + \"test/text_files/\"\n",
    "test_files = [f for f in os.listdir(test_path) if os.path.isfile(test_path + f) and f.split('.')[-1] == 'txt']\n",
    "test_data = load_text_files(test_files, test_path)\n",
    "df_text_test = pd.DataFrame({'doc_id': [s.split('.txt')[0] for s in test_files], 'raw_text': test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner = pd.read_table(corpus_path + \"train/trainX.tsv\", sep='\\t', header=None)\n",
    "df_codes_train_ner.columns = [\"doc_id\", \"type\", \"code\", \"word\", \"location\"]\n",
    "df_codes_train_ner = df_codes_train_ner[~df_codes_train_ner[['doc_id', 'type', 'location']].duplicated(keep='first')]\n",
    "df_codes_train_ner['disc'] = df_codes_train_ner['location'].apply(lambda x: ';' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one type of annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner = df_codes_train_ner[df_codes_train_ner['type'] == TYPE_ANN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final = process_labels_norm_prueba(df_ann=df_codes_train_ner[[\"doc_id\", \"type\", \"code\", \"word\", \"location\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove annotations of zero length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final['length'] = df_codes_train_ner_final.apply(lambda x: x['end'] - x['start'], axis=1)\n",
    "df_codes_train_ner_final = df_codes_train_ner_final[df_codes_train_ner_final['length'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate continuous and discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continiuous\n",
    "df_codes_train_ner_final_cont = df_codes_train_ner_final[df_codes_train_ner_final['disc'] == 0].copy()\n",
    "df_codes_train_ner_final_cont['disc'] = df_codes_train_ner_final_cont['disc'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discontinuous\n",
    "df_codes_train_ner_final_disc = restore_disc_ann(df_ann=df_codes_train_ner[df_codes_train_ner['disc']], \n",
    "                    df_ann_final=df_codes_train_ner_final[df_codes_train_ner_final['disc'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final_disc['start'] = df_codes_train_ner_final_disc['location'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df_codes_train_ner_final_disc['end'] = df_codes_train_ner_final_disc['location'].apply(lambda x: int(x.split(' ')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate continuous and discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat\n",
    "cols_concat = ['doc_id', 'type', 'code', 'word', 'location', 'start', 'end', 'disc']\n",
    "df_codes_train_ner_final = pd.concat([df_codes_train_ner_final_cont[cols_concat], \n",
    "                                      df_codes_train_ner_final_disc[cols_concat]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we remove the right-to-left (text wise) discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final['direction'] = df_codes_train_ner_final.apply(check_ann_left_right_direction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final = df_codes_train_ner_final[df_codes_train_ner_final['direction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only select the annotations fully contained in a single sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence-Split data\n",
    "ss_sub_corpus_path = ss_corpus_path + \"train/\"\n",
    "ss_files = [f for f in os.listdir(ss_sub_corpus_path) if os.path.isfile(ss_sub_corpus_path + f)]\n",
    "ss_dict_train = load_ss_files(ss_files, ss_sub_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mult_sent_train, df_one_sent_train, df_no_sent_train = check_ann_span_sent(df_ann=df_codes_train_ner_final, \n",
    "                                                                             ss_dict=ss_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final = df_one_sent_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    1205\n",
      "True      355\n",
      "Name: disc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_codes_train_ner_final.disc.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_train_ner_final.sort_values(['doc_id', 'start', 'end'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPE_TASK == 'd':\n",
    "    df_codes_train_ner_final[\"code_pre\"] = df_codes_train_ner_final[\"code\"].apply(lambda x: x.split('.')[0])\n",
    "    df_codes_train_ner_final[\"code_suf\"] = df_codes_train_ner_final[\"code\"].apply(lambda x: None if not '.' in x else x.split('.')[1])\n",
    "else:\n",
    "    df_codes_train_ner_final[\"code_pre\"] = df_codes_train_ner_final[\"code\"].apply(lambda x: x[:4])\n",
    "    df_codes_train_ner_final[\"code_suf\"] = df_codes_train_ner_final[\"code\"].apply(lambda x: None if len(x) < 7 else x[4:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner = pd.read_table(corpus_path + \"dev/devX.tsv\", sep='\\t', header=None)\n",
    "df_codes_dev_ner.columns = [\"doc_id\", \"type\", \"code\", \"word\", \"location\"]\n",
    "df_codes_dev_ner = df_codes_dev_ner[~df_codes_dev_ner[['doc_id', 'type', 'location']].duplicated(keep='first')]\n",
    "df_codes_dev_ner['disc'] = df_codes_dev_ner['location'].apply(lambda x: ';' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one type of annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner = df_codes_dev_ner[df_codes_dev_ner['type'] == TYPE_ANN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final = process_labels_norm_prueba(df_ann=df_codes_dev_ner[[\"doc_id\", \"type\", \"code\", \"word\", \"location\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove annotations of zero length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final['length'] = df_codes_dev_ner_final.apply(lambda x: x['end'] - x['start'], axis=1)\n",
    "df_codes_dev_ner_final = df_codes_dev_ner_final[df_codes_dev_ner_final['length'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate continuous and discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continiuous\n",
    "df_codes_dev_ner_final_cont = df_codes_dev_ner_final[df_codes_dev_ner_final['disc'] == 0].copy()\n",
    "df_codes_dev_ner_final_cont['disc'] = df_codes_dev_ner_final_cont['disc'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discontinuous\n",
    "df_codes_dev_ner_final_disc = restore_disc_ann(df_ann=df_codes_dev_ner[df_codes_dev_ner['disc']], \n",
    "                    df_ann_final=df_codes_dev_ner_final[df_codes_dev_ner_final['disc'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final_disc['start'] = df_codes_dev_ner_final_disc['location'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df_codes_dev_ner_final_disc['end'] = df_codes_dev_ner_final_disc['location'].apply(lambda x: int(x.split(' ')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate continuous and discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat\n",
    "cols_concat = ['doc_id', 'type', 'code', 'word', 'location', 'start', 'end', 'disc']\n",
    "df_codes_dev_ner_final = pd.concat([df_codes_dev_ner_final_cont[cols_concat], \n",
    "                                      df_codes_dev_ner_final_disc[cols_concat]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we remove the right-to-left (text wise) discontinuous annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final['direction'] = df_codes_dev_ner_final.apply(check_ann_left_right_direction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final = df_codes_dev_ner_final[df_codes_dev_ner_final['direction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only select the annotations fully contained in a single sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence-Split data\n",
    "ss_sub_corpus_path = ss_corpus_path + \"dev/\"\n",
    "ss_files = [f for f in os.listdir(ss_sub_corpus_path) if os.path.isfile(ss_sub_corpus_path + f)]\n",
    "ss_dict_dev = load_ss_files(ss_files, ss_sub_corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mult_sent_dev, df_one_sent_dev, df_no_sent_dev = check_ann_span_sent(df_ann=df_codes_dev_ner_final, \n",
    "                                                                             ss_dict=ss_dict_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final = df_one_sent_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    575\n",
      "True     202\n",
      "Name: disc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_codes_dev_ner_final.disc.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_dev_ner_final.sort_values(['doc_id', 'start', 'end'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPE_TASK == 'd':\n",
    "    df_codes_dev_ner_final[\"code_pre\"] = df_codes_dev_ner_final[\"code\"].apply(lambda x: x.split('.')[0])\n",
    "    df_codes_dev_ner_final[\"code_suf\"] = df_codes_dev_ner_final[\"code\"].apply(lambda x: None if not '.' in x else x.split('.')[1])\n",
    "else:\n",
    "    df_codes_dev_ner_final[\"code_pre\"] = df_codes_dev_ner_final[\"code\"].apply(lambda x: x[:4])\n",
    "    df_codes_dev_ner_final[\"code_suf\"] = df_codes_dev_ner_final[\"code\"].apply(lambda x: None if len(x) < 7 else x[4:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_codes_pre = sorted(set(df_codes_dev_ner_final[\"code_pre\"].values).union(set(\n",
    "    df_codes_train_ner_final[\"code_pre\"].values\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dev_codes_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev_codes_suf = sorted(set(df_codes_dev_ner_final[df_codes_dev_ner_final['code_suf'].apply(lambda x: x is not None)][\"code_suf\"].values).union(set(df_codes_train_ner_final[df_codes_train_ner_final['code_suf'].apply(lambda x: x is not None)][\"code_suf\"].values))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dev_codes_suf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IOB-2 and Clinical-Coding label encoders as dict (more computationally efficient)\n",
    "iob_lab_encoder = {\"B\": 0, \"I\": 1, \"O\": 2}\n",
    "iob_lab_decoder = {0: \"B\", 1: \"I\", 2: \"O\"}\n",
    "\n",
    "# Code-pre\n",
    "code_pre_lab_encoder = {}\n",
    "code_pre_lab_decoder = {}\n",
    "i = 0\n",
    "for code in train_dev_codes_pre:\n",
    "    code_pre_lab_encoder[code] = i\n",
    "    code_pre_lab_decoder[i] = code\n",
    "    i += 1\n",
    "    \n",
    "code_pre_lab_encoder[\"O\"] = i\n",
    "code_pre_lab_decoder[i] = \"O\"\n",
    "\n",
    "# Code-suf\n",
    "code_suf_lab_encoder = {}\n",
    "code_suf_lab_decoder = {}\n",
    "i = 0\n",
    "for code in train_dev_codes_suf:\n",
    "    code_suf_lab_encoder[code] = i\n",
    "    code_suf_lab_decoder[i] = code\n",
    "    i += 1\n",
    "\n",
    "# Add \"O\" label to code-suf, since some codes do not have suffix\n",
    "code_suf_lab_encoder[\"O\"] = i\n",
    "code_suf_lab_decoder[i] = \"O\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n"
     ]
    }
   ],
   "source": [
    "print(len(iob_lab_encoder), len(iob_lab_decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447 447\n"
     ]
    }
   ],
   "source": [
    "print(len(code_pre_lab_encoder), len(code_pre_lab_decoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64\n"
     ]
    }
   ],
   "source": [
    "print(len(code_suf_lab_encoder), len(code_suf_lab_decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENS_EVAL_STRAT = 'sum'\n",
    "RES_DIR_ENS = RES_DIR + \"ensemble/\"\n",
    "\n",
    "subtask = 'norm'\n",
    "subtask_ann = subtask + '-iob_code_suf'\n",
    "\n",
    "CODE_SEP = '.' if TYPE_ANN == 'DIAGNOSTICO' else ''\n",
    "\n",
    "arr_exec = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ens_performance(ens_name, ner_model_name, arr_model_name, \n",
    "                    res_dir=RES_DIR_ENS, prefix_name='', arr_exec=arr_exec, \n",
    "                    df_gs=df_test_gs, \n",
    "                    code_pre_lab_decoder=code_pre_lab_decoder, \n",
    "                    code_suf_lab_decoder=code_suf_lab_decoder, \n",
    "                    ens_eval_strategy=ENS_EVAL_STRAT, \n",
    "                    subtask_ann=subtask_ann):\n",
    "    df_ens_ner = pd.read_csv(res_dir + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             ner_model_name + \"_ann.csv\", header=0, sep='\\t')\n",
    "    ens_preds_code_pre, ens_preds_code_suf = [], []\n",
    "    for model_name in arr_model_name:\n",
    "        for i_exec in arr_exec:\n",
    "            ens_preds_code_pre.append(np.load(file=res_dir + prefix_name + \"test_preds_code_pre_ens_ner_\" + ens_name + \\\n",
    "                                              \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\"))\n",
    "            ens_preds_code_suf.append(np.load(file=res_dir + prefix_name + \"test_preds_code_suf_ens_ner_\" + ens_name + \\\n",
    "                                              \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\"))\n",
    "\n",
    "    # Sanity check: all preds array have the same shape\n",
    "    assert len(ens_preds_code_pre) == len(ens_preds_code_suf)\n",
    "    for i in range(len(ens_preds_code_pre) - 1):\n",
    "        assert ens_preds_code_pre[i].shape == ens_preds_code_pre[i + 1].shape\n",
    "        assert ens_preds_code_suf[i].shape == ens_preds_code_suf[i + 1].shape\n",
    "    \n",
    "    print(\"Nº executions:\", len(ens_preds_code_pre))\n",
    "\n",
    "    if ens_eval_strategy == 'sum':\n",
    "        ens_code_pre = np.sum(ens_preds_code_pre, axis=0)\n",
    "        ens_code_suf = np.sum(ens_preds_code_suf, axis=0)\n",
    "    else: # default 'prod'\n",
    "        ens_code_pre = np.prod(ens_preds_code_pre, axis=0)\n",
    "        ens_code_suf = np.prod(ens_preds_code_suf, axis=0)\n",
    "\n",
    "    df_ens_preds = cls_code_norm_preds_brat_format(\n",
    "        y_pred_cls=[ens_code_pre, ens_code_suf], \n",
    "        df_pred_ner=df_ens_ner, \n",
    "        code_decoder_list=[code_pre_lab_decoder, code_suf_lab_decoder],\n",
    "        subtask=subtask_ann,\n",
    "        code_sep=CODE_SEP,\n",
    "        codes_pre_o_mask=None,\n",
    "        codes_pre_suf_mask=None\n",
    "    )\n",
    "    \n",
    "    # Adapt to CodiEsp format\n",
    "    df_ens_preds['label_pred'] = TYPE_ANN\n",
    "    df_ens_preds['pos_pred'] = [str(row['start']) + ' ' + str(row['end']) for index, row in df_ens_preds.iterrows()]\n",
    "    df_ens_preds = df_ens_preds.rename(columns={'code_pred': 'code'})\n",
    "    df_ens_preds = df_ens_preds[['clinical_case', 'pos_pred', 'label_pred', 'code']]\n",
    "\n",
    "    return df_ens_preds, calculate_codiesp_x_metrics(\n",
    "        df_gs=df_gs[df_gs['label_gs'] == TYPE_ANN], \n",
    "        df_pred=format_codiesp_x_pred_df(\n",
    "            df_run=df_ens_preds,\n",
    "            valid_codes=valid_codes\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'beto'\n",
    "ner_model_name = ens_name\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº executions: 5\n",
      "(0.6661, 0.4471, 0.5351)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BETO-Galén"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'beto_galen'\n",
    "ner_model_name = 'beto_galen'\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº executions: 5\n",
      "(0.6571, 0.4687, 0.5471)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'mbert'\n",
    "ner_model_name = 'mbert'\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº executions: 5\n",
      "(0.6684, 0.4471, 0.5358)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mBERT-Galén"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'mbert_galen'\n",
    "ner_model_name = 'mbert_galen'\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº executions: 5\n",
      "(0.6823, 0.479, 0.5628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'xlmr'\n",
    "ner_model_name = 'xlmr'\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº executions: 5\n",
      "(0.6546, 0.4528, 0.5353)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM-R-Galén"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = 'xlmr_galen'\n",
    "ner_model_name = 'xlmr_galen'\n",
    "arr_model_name = [ens_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº executions: 5\n",
      "(0.6609, 0.4744, 0.5523)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BETO + BETO-Galén"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model_name = ['beto', 'beto_galen']\n",
    "ens_name = '_'.join(arr_model_name)\n",
    "ner_model_name = 'beto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº executions: 10\n",
      "(0.6778, 0.4619, 0.5494)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mBERT + mBERT-Galén"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model_name = ['mbert', 'mbert_galen']\n",
    "ens_name = '_'.join(arr_model_name)\n",
    "ner_model_name = 'mbert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº executions: 10\n",
      "(0.701, 0.4642, 0.5585)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLM-R + XLM-R-Galén"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_model_name = ['xlmr', 'xlmr_galen']\n",
    "ens_name = '_'.join(arr_model_name)\n",
    "ner_model_name = 'xlmr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº executions: 10\n",
      "(0.6726, 0.4699, 0.5532)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_ENS_PREF = \"multi_model_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_empty_ner_preds(ens_name, ner_model_name, arr_model_name, \n",
    "                        res_dir=RES_DIR_ENS, empty_value=0, \n",
    "                        prefix_name=MULTI_ENS_PREF):\n",
    "    \"\"\"\n",
    "    Considering a set of NER predictions as reference, this procedure inserts empty code-pre and code-suf\n",
    "    samples in the case a certain model does not predict a reference NER sample.\n",
    "    \"\"\"\n",
    "    # Load reference DF of NER predictions\n",
    "    df_ref_ens_ner = pd.read_csv(res_dir + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                                 ner_model_name + \"_ann.csv\", header=0, sep='\\t')\n",
    "    for model_name in arr_model_name:\n",
    "        # Load DF of NER predictions from the current model\n",
    "        df_ens_ner = pd.read_csv(res_dir + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                                 model_name + \"_ann.csv\", header=0, sep='\\t')\n",
    "        assert df_ens_ner.shape[0] <= df_ref_ens_ner.shape[0]\n",
    "        arr_i_insert = []\n",
    "        if df_ens_ner.shape[0] < df_ref_ens_ner.shape[0]:\n",
    "            # Check the indices of the absent samples, i.e. reference NER samples that are not predicted by the current model\n",
    "            absent_samples = set(df_ref_ens_ner.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), \n",
    "                                                      axis=1)) - \\\n",
    "                             set(df_ens_ner.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), \n",
    "                                                  axis=1))\n",
    "            assert len(absent_samples) == df_ref_ens_ner.shape[0] - df_ens_ner.shape[0]\n",
    "            arr_i_absent = []\n",
    "            for s in absent_samples:\n",
    "                s = s.split('|')\n",
    "                s_index = df_ref_ens_ner[(df_ref_ens_ner['clinical_case'] == s[0]) & (df_ref_ens_ner['location'] == s[1])].index[0]\n",
    "                arr_i_absent.append(np.where(df_ref_ens_ner.index.values == s_index)[0][0])\n",
    "            assert len(arr_i_absent) > 0\n",
    "            # Sort indices of absent samples\n",
    "            arr_i_absent = np.sort(arr_i_absent)\n",
    "            # Convert indices of absent samples to insertion indices\n",
    "            arr_i_insert.append(arr_i_absent[0])\n",
    "            for i in range(1, len(arr_i_absent)):\n",
    "                arr_i_insert.append(arr_i_absent[i] - i) # needs to be sanity checked\n",
    "        ## Insert empty values for the absent samples (if any)\n",
    "        for i_exec in arr_exec:\n",
    "            # Load predictions of both code prefix and suffix\n",
    "            preds_code_pre = np.load(file=res_dir + \"test_preds_code_pre_ens_ner_\" + ens_name + \\\n",
    "                                     \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\")\n",
    "            preds_code_suf = np.load(file=res_dir + \"test_preds_code_suf_ens_ner_\" + ens_name + \\\n",
    "                                     \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\")\n",
    "            preds_code_pre = np.insert(arr=preds_code_pre, obj=arr_i_insert, values=empty_value, axis=0)\n",
    "            preds_code_suf = np.insert(arr=preds_code_suf, obj=arr_i_insert, values=empty_value, axis=0)\n",
    "            # Save predictions after insertion\n",
    "            np.save(file=res_dir + prefix_name + \"test_preds_code_pre_ens_ner_\" + ens_name + \\\n",
    "                    \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\",\n",
    "                    arr=preds_code_pre)\n",
    "            np.save(file=res_dir + prefix_name + \"test_preds_code_suf_ens_ner_\" + ens_name + \\\n",
    "                    \"_\" + TYPE_TASK + \"_hier_task_cls_\" + model_name + \"_\" + str(i_exec) + \".npy\",\n",
    "                    arr=preds_code_suf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BETO + mBERT + XLM-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = \"beto_mbert_xlmr\"\n",
    "arr_model_name = ['beto', 'mbert', 'xlmr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_iob = pd.read_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_iob_\" + ens_name + \".csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_iob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_beto = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[0] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 5)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_beto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_beto = set(df_ens_ner_beto.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_beto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_mbert = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[1] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 5)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_mbert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_mbert = set(df_ens_ner_mbert.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_mbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_xlmr = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[2] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(696, 5)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_xlmr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_xlmr = set(df_ens_ner_xlmr.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_xlmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set_ens_ner_beto == set_ens_ner_mbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_xlmr - set_ens_ner_beto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_beto - set_ens_ner_xlmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BETO, mBERT and XLM-R models could be empoyed as NER-reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model_name = \"xlmr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_empty_ner_preds(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name, \n",
    "    empty_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº executions: 15\n",
      "(0.6877, 0.4585, 0.5502)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name,\n",
    "    prefix_name=MULTI_ENS_PREF\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BETO-Galén + mBERT-Galén + XLM-R-Galén"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_name = \"beto_galen_mbert_galen_xlmr_galen\"\n",
    "arr_model_name = ['beto_galen', 'mbert_galen', 'xlmr_galen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_iob = pd.read_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_iob_\" + ens_name + \".csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737, 5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_iob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_beto = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[0] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(736, 5)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_beto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_beto = set(df_ens_ner_beto.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "736"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_beto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_mbert = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[1] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(736, 5)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_mbert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_mbert = set(df_ens_ner_mbert.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "736"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_mbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ner_xlmr = pd.read_csv(RES_DIR_ENS + \"df_test_preds_ens_ner_\" + ens_name + \"_\" + TYPE_TASK + \"_hier_task_cls_\" + \\\n",
    "                             arr_model_name[2] + \"_ann.csv\", header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(736, 5)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ens_ner_xlmr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ens_ner_xlmr = set(df_ens_ner_xlmr.apply(lambda x: str(x['clinical_case']) + '|' + str(x['location']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "736"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_xlmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set_ens_ner_beto == set_ens_ner_mbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_xlmr - set_ens_ner_beto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_ens_ner_beto - set_ens_ner_xlmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BETO-Galén, mBERT-Galén and XLM-R-Galén models could be empoyed as NER-reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model_name = \"xlmr_galen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_empty_ner_preds(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name, \n",
    "    empty_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº executions: 15\n",
      "(0.6796, 0.4778, 0.5611)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df_ens_ann, res_metrics = ens_performance(\n",
    "    ens_name=ens_name, \n",
    "    ner_model_name=ner_model_name, \n",
    "    arr_model_name=arr_model_name,\n",
    "    prefix_name=MULTI_ENS_PREF\n",
    ")\n",
    "print(res_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_ens_res[ens_name] = res_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ens_ann.to_csv(RES_DIR_ENS + \"df_test_preds_\" + TYPE_TASK + \"_hier_task_cls_\" + '_'.join(arr_model_name) + \\\n",
    "                  \".csv\", index=False, header=True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dic_ens_res, index=[\"P\", \"R\", \"F1\"]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>0.6661</td>\n",
       "      <td>0.4471</td>\n",
       "      <td>0.5351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>0.6571</td>\n",
       "      <td>0.4687</td>\n",
       "      <td>0.5471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>0.6684</td>\n",
       "      <td>0.4471</td>\n",
       "      <td>0.5358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>0.6823</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.5628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>0.6546</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.5353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>0.6609</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.5523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_beto_galen</th>\n",
       "      <td>0.6778</td>\n",
       "      <td>0.4619</td>\n",
       "      <td>0.5494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_mbert_galen</th>\n",
       "      <td>0.7010</td>\n",
       "      <td>0.4642</td>\n",
       "      <td>0.5585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_xlmr_galen</th>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.5532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_mbert_xlmr</th>\n",
       "      <td>0.6877</td>\n",
       "      <td>0.4585</td>\n",
       "      <td>0.5502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen_mbert_galen_xlmr_galen</th>\n",
       "      <td>0.6796</td>\n",
       "      <td>0.4778</td>\n",
       "      <td>0.5611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        P       R      F1\n",
       "beto                               0.6661  0.4471  0.5351\n",
       "beto_galen                         0.6571  0.4687  0.5471\n",
       "mbert                              0.6684  0.4471  0.5358\n",
       "mbert_galen                        0.6823  0.4790  0.5628\n",
       "xlmr                               0.6546  0.4528  0.5353\n",
       "xlmr_galen                         0.6609  0.4744  0.5523\n",
       "beto_beto_galen                    0.6778  0.4619  0.5494\n",
       "mbert_mbert_galen                  0.7010  0.4642  0.5585\n",
       "xlmr_xlmr_galen                    0.6726  0.4699  0.5532\n",
       "beto_mbert_xlmr                    0.6877  0.4585  0.5502\n",
       "beto_galen_mbert_galen_xlmr_galen  0.6796  0.4778  0.5611"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "df = format_df_paper(\n",
    "    model_performance(\n",
    "        {\n",
    "            'beto': [1, 2, 3, 4, 5], \n",
    "            'beto_galen': [1, 2, 3, 4, 5],\n",
    "            'mbert': [1, 2, 3, 4, 5], \n",
    "            'mbert_galen': [1, 2, 3, 4, 5],\n",
    "            'xlmr': [1, 2, 3, 4, 5], \n",
    "            'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "        },\n",
    "        multi_task=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_avg_std</th>\n",
       "      <th>P_max</th>\n",
       "      <th>R_avg_std</th>\n",
       "      <th>R_max</th>\n",
       "      <th>F1_avg_std</th>\n",
       "      <th>F1_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>.651 ± .008</td>\n",
       "      <td>.662</td>\n",
       "      <td>.42 ± .007</td>\n",
       "      <td>.428</td>\n",
       "      <td>.511 ± .007</td>\n",
       "      <td>.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>.645 ± .028</td>\n",
       "      <td>.683</td>\n",
       "      <td>.438 ± .013</td>\n",
       "      <td>.46</td>\n",
       "      <td>.521 ± .009</td>\n",
       "      <td>.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>.623 ± .006</td>\n",
       "      <td>.63</td>\n",
       "      <td>.424 ± .011</td>\n",
       "      <td>.44</td>\n",
       "      <td>.504 ± .009</td>\n",
       "      <td>.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>.643 ± .016</td>\n",
       "      <td>.661</td>\n",
       "      <td>.434 ± .008</td>\n",
       "      <td>.442</td>\n",
       "      <td>.518 ± .01</td>\n",
       "      <td>.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>.613 ± .013</td>\n",
       "      <td>.631</td>\n",
       "      <td>.426 ± .011</td>\n",
       "      <td>.439</td>\n",
       "      <td>.502 ± .006</td>\n",
       "      <td>.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>.636 ± .023</td>\n",
       "      <td>.659</td>\n",
       "      <td>.435 ± .01</td>\n",
       "      <td>.447</td>\n",
       "      <td>.517 ± .007</td>\n",
       "      <td>.524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P_avg_std P_max    R_avg_std R_max   F1_avg_std F1_max\n",
       "beto         .651 ± .008  .662   .42 ± .007  .428  .511 ± .007    .52\n",
       "beto_galen   .645 ± .028  .683  .438 ± .013   .46  .521 ± .009   .531\n",
       "mbert        .623 ± .006   .63  .424 ± .011   .44  .504 ± .009   .518\n",
       "mbert_galen  .643 ± .016  .661  .434 ± .008  .442   .518 ± .01   .526\n",
       "xlmr         .613 ± .013  .631  .426 ± .011  .439  .502 ± .006   .511\n",
       "xlmr_galen   .636 ± .023  .659   .435 ± .01  .447  .517 ± .007   .524"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the (F1) performance of all executions of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_model_f1_values(dict_names_execs, df_gs=df_test_gs):\n",
    "    \"\"\"\n",
    "    Generate a vector containing the F1 performance of all executions of all models, in the given order.\n",
    "    \n",
    "    dict_names_execs: each key is a string with the model name, and \n",
    "                      each value is a list with the random execs of the corresponding model.\n",
    "    \"\"\"\n",
    "    arr_values = []\n",
    "    for model_name in dict_names_execs:\n",
    "        for i_exec in dict_names_execs[model_name]:\n",
    "            df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_multi_task_ner_\" + str(i_exec) + \"_\" + TYPE_TASK + \\\n",
    "                    \"_hier_task_cls_\" + str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "            _, _, f1 = calculate_codiesp_x_metrics(\n",
    "                df_gs=df_gs[df_gs['label_gs'] == TYPE_ANN], \n",
    "                df_pred=format_codiesp_x_pred_df(\n",
    "                    df_run=df_test_preds,\n",
    "                    valid_codes=valid_codes\n",
    "                )\n",
    "            )\n",
    "            arr_values.append(f1)\n",
    "    return arr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "/home/comun/guillermo/NLP/scripts/../utils/nlp_utils.py:4918: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
     ]
    }
   ],
   "source": [
    "arr_val = multi_model_f1_values(\n",
    "    {\n",
    "        'beto': [1, 2, 3, 4, 5], \n",
    "        'beto_galen': [1, 2, 3, 4, 5],\n",
    "        'mbert': [1, 2, 3, 4, 5], \n",
    "        'mbert_galen': [1, 2, 3, 4, 5],\n",
    "        'xlmr': [1, 2, 3, 4, 5], \n",
    "        'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(arr_val).to_csv(RES_DIR + \"norm_f1_exec_\" + TYPE_TASK + \"_multi_task_ner_hier_task.csv\", index=False, header=False, sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
