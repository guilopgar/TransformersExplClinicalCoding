{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_path = \"../utils/\"\n",
    "corpus_path = \"../datasets/cantemist_v6/\"\n",
    "subtask = \"norm\"\n",
    "sub_task_path = \"cantemist-\" + subtask + \"/\"\n",
    "test_gs_path = corpus_path + \"test-set/\" + sub_task_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 08:40:02.951142: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Auxiliary components\n",
    "import sys\n",
    "sys.path.insert(0, utils_path)\n",
    "from nlp_utils import *\n",
    "\n",
    "RES_DIR = \"../results/Cantemist/final_exec/\"\n",
    "\n",
    "# GS data\n",
    "df_test_gs = format_ner_gs(test_gs_path, subtask=subtask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ner_norm_performance(model_name, arr_execs):\n",
    "    \"\"\"\n",
    "    Sanity-check procedure that prints the NER-NORM performance of each single model execution.\n",
    "    \"\"\"\n",
    "    for i_exec in arr_execs:\n",
    "        print(\"Exec \" + str(i_exec) + \":\")\n",
    "        df_test_preds_ner = pd.read_csv(RES_DIR + \"df_test_preds_ner_c_multi_task_\" + \\\n",
    "                str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "        print(\"NER performance:\", calculate_ner_metrics(\n",
    "            gs=df_test_gs, \n",
    "            pred=format_ner_pred_df(\n",
    "                gs_path=test_gs_path, \n",
    "                df_preds=df_test_preds_ner, \n",
    "                subtask='ner'\n",
    "            ),\n",
    "            subtask='ner'\n",
    "        ))\n",
    "        df_test_preds_norm = pd.read_csv(RES_DIR + \"df_test_preds_norm_c_multi_task_\" + \\\n",
    "                str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "        print(\"NORM performance:\", calculate_ner_metrics(\n",
    "            gs=df_test_gs, \n",
    "            pred=format_ner_pred_df(\n",
    "                gs_path=test_gs_path, \n",
    "                df_preds=df_test_preds_norm, \n",
    "                subtask=subtask\n",
    "            ),\n",
    "            subtask=subtask\n",
    "        ), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(dict_names_execs, subtask='norm', \n",
    "                      df_gs=df_test_gs, path_gs=test_gs_path,\n",
    "                      round_n=3):\n",
    "    \"\"\"\n",
    "    Generate a pd.DataFrame with the statistics of the performance of each model.\n",
    "    \n",
    "    dict_names_execs: each key is a string with the model name, and \n",
    "                      each value is a list with the random execs of the corresponding model.\n",
    "    \"\"\"\n",
    "    res_dict = {}\n",
    "    for model_name in dict_names_execs:\n",
    "        p_res, r_res, f1_res = [], [], []\n",
    "        for i_exec in dict_names_execs[model_name]:\n",
    "            df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_\" + subtask + \"_c_multi_task_\" + \\\n",
    "                    str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "            p, r, f1 = calculate_ner_metrics(\n",
    "                gs=df_gs, \n",
    "                pred=format_ner_pred_df(\n",
    "                    gs_path=path_gs, \n",
    "                    df_preds=df_test_preds, \n",
    "                    subtask=subtask\n",
    "                ),\n",
    "                subtask=subtask\n",
    "            )\n",
    "            p_res.append(p)\n",
    "            r_res.append(r)\n",
    "            f1_res.append(f1)\n",
    "        p_res_stat = pd.Series(p_res).describe()\n",
    "        r_res_stat = pd.Series(r_res).describe()\n",
    "        f1_res_stat = pd.Series(f1_res).describe()\n",
    "        res_dict[model_name] = {\"P_avg\": round(p_res_stat['mean'], round_n), \"P_std\": round(p_res_stat['std'], round_n), \n",
    "                                \"P_max\": round(p_res_stat['max'], round_n),\n",
    "                                \"R_avg\": round(r_res_stat['mean'], round_n), \"R_std\": round(r_res_stat['std'], round_n), \n",
    "                                \"R_max\": round(r_res_stat['max'], round_n),\n",
    "                                \"F1_avg\": round(f1_res_stat['mean'], round_n), \"F1_std\": round(f1_res_stat['std'], round_n), \n",
    "                                \"F1_max\": round(f1_res_stat['max'], round_n)}\n",
    "    return pd.DataFrame(res_dict, index=[\"P_avg\", \"P_std\", \"P_max\", \n",
    "                                         \"R_avg\", \"R_std\", \"R_max\", \n",
    "                                         \"F1_avg\", \"F1_std\", \"F1_max\"]).transpose()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df_paper(df_res):\n",
    "    arr_metrics = [\"P\", \"R\", \"F1\"]\n",
    "    arr_cols = []\n",
    "    for metric in arr_metrics:\n",
    "        df_res[metric + '_avg_std'] = df_res.apply(\n",
    "            lambda x: \".\" + str(x[metric + '_avg']).split('.')[-1] + \" ± \" + \\\n",
    "                \".\" + str(x[metric + '_std']).split('.')[-1], \n",
    "            axis=1\n",
    "        )\n",
    "        df_res[metric + '_max'] = df_res[metric + '_max'].apply(\n",
    "            lambda x: \".\" + str(x).split('.')[-1]\n",
    "        )\n",
    "        arr_cols += [metric + '_avg_std', metric + '_max']\n",
    "    return df_res[arr_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec 1:\n",
      "NER performance: (0.855, 0.8615, 0.8582)\n",
      "NORM performance: (0.8044, 0.8106, 0.8075)\n",
      "\n",
      "Exec 2:\n",
      "NER performance: (0.8559, 0.8566, 0.8562)\n",
      "NORM performance: (0.8058, 0.8065, 0.8062)\n",
      "\n",
      "Exec 3:\n",
      "NER performance: (0.8631, 0.8643, 0.8637)\n",
      "NORM performance: (0.8114, 0.8126, 0.812)\n",
      "\n",
      "Exec 4:\n",
      "NER performance: (0.8597, 0.8516, 0.8556)\n",
      "NORM performance: (0.8083, 0.8007, 0.8045)\n",
      "\n",
      "Exec 5:\n",
      "NER performance: (0.8435, 0.8632, 0.8532)\n",
      "NORM performance: (0.7972, 0.8159, 0.8064)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_name = \"mbert\"\n",
    "execs = [1, 2, 3, 4, 5]\n",
    "\n",
    "check_ner_norm_performance(model_name=m_name, arr_execs=execs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec 1:\n",
      "NER performance: (0.8653, 0.8643, 0.8648)\n",
      "NORM performance: (0.8101, 0.8092, 0.8097)\n",
      "\n",
      "Exec 2:\n",
      "NER performance: (0.8822, 0.8593, 0.8706)\n",
      "NORM performance: (0.8302, 0.8087, 0.8193)\n",
      "\n",
      "Exec 3:\n",
      "NER performance: (0.8529, 0.8748, 0.8637)\n",
      "NORM performance: (0.8011, 0.8216, 0.8113)\n",
      "\n",
      "Exec 4:\n",
      "NER performance: (0.8694, 0.8665, 0.8679)\n",
      "NORM performance: (0.8202, 0.8175, 0.8189)\n",
      "\n",
      "Exec 5:\n",
      "NER performance: (0.864, 0.8637, 0.8639)\n",
      "NORM performance: (0.8136, 0.8134, 0.8135)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_name = \"mbert_galen\"\n",
    "execs = [1, 2, 3, 4, 5]\n",
    "\n",
    "check_ner_norm_performance(model_name=m_name, arr_execs=execs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_avg</th>\n",
       "      <th>P_std</th>\n",
       "      <th>P_max</th>\n",
       "      <th>R_avg</th>\n",
       "      <th>R_std</th>\n",
       "      <th>R_max</th>\n",
       "      <th>F1_avg</th>\n",
       "      <th>F1_std</th>\n",
       "      <th>F1_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             P_avg  P_std  P_max  R_avg  R_std  R_max  F1_avg  F1_std  F1_max\n",
       "beto         0.802  0.011  0.820  0.797  0.005  0.805   0.799   0.004   0.804\n",
       "beto_galen   0.805  0.005  0.810  0.806  0.007  0.816   0.805   0.004   0.813\n",
       "mbert        0.805  0.005  0.811  0.809  0.006  0.816   0.807   0.003   0.812\n",
       "mbert_galen  0.815  0.011  0.830  0.814  0.006  0.822   0.815   0.004   0.819\n",
       "xlmr         0.802  0.007  0.814  0.806  0.006  0.816   0.804   0.005   0.810\n",
       "xlmr_galen   0.812  0.008  0.826  0.812  0.003  0.817   0.812   0.004   0.818"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance(\n",
    "    {\n",
    "        'beto': [1, 2, 3, 4, 5], \n",
    "        'beto_galen': [1, 2, 3, 4, 5],\n",
    "        'mbert': [1, 2, 3, 4, 5], \n",
    "        'mbert_galen': [1, 2, 3, 4, 5],\n",
    "        'xlmr': [1, 2, 3, 4, 5], \n",
    "        'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "    }, \n",
    "    subtask='norm'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_avg_std</th>\n",
       "      <th>P_max</th>\n",
       "      <th>R_avg_std</th>\n",
       "      <th>R_max</th>\n",
       "      <th>F1_avg_std</th>\n",
       "      <th>F1_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>.802 ± .011</td>\n",
       "      <td>.82</td>\n",
       "      <td>.797 ± .005</td>\n",
       "      <td>.805</td>\n",
       "      <td>.799 ± .004</td>\n",
       "      <td>.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>.805 ± .005</td>\n",
       "      <td>.81</td>\n",
       "      <td>.806 ± .007</td>\n",
       "      <td>.816</td>\n",
       "      <td>.805 ± .004</td>\n",
       "      <td>.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>.805 ± .005</td>\n",
       "      <td>.811</td>\n",
       "      <td>.809 ± .006</td>\n",
       "      <td>.816</td>\n",
       "      <td>.807 ± .003</td>\n",
       "      <td>.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>.815 ± .011</td>\n",
       "      <td>.83</td>\n",
       "      <td>.814 ± .006</td>\n",
       "      <td>.822</td>\n",
       "      <td>.815 ± .004</td>\n",
       "      <td>.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>.802 ± .007</td>\n",
       "      <td>.814</td>\n",
       "      <td>.806 ± .006</td>\n",
       "      <td>.816</td>\n",
       "      <td>.804 ± .005</td>\n",
       "      <td>.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>.812 ± .008</td>\n",
       "      <td>.826</td>\n",
       "      <td>.812 ± .003</td>\n",
       "      <td>.817</td>\n",
       "      <td>.812 ± .004</td>\n",
       "      <td>.818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P_avg_std P_max    R_avg_std R_max   F1_avg_std F1_max\n",
       "beto         .802 ± .011   .82  .797 ± .005  .805  .799 ± .004   .804\n",
       "beto_galen   .805 ± .005   .81  .806 ± .007  .816  .805 ± .004   .813\n",
       "mbert        .805 ± .005  .811  .809 ± .006  .816  .807 ± .003   .812\n",
       "mbert_galen  .815 ± .011   .83  .814 ± .006  .822  .815 ± .004   .819\n",
       "xlmr         .802 ± .007  .814  .806 ± .006  .816  .804 ± .005    .81\n",
       "xlmr_galen   .812 ± .008  .826  .812 ± .003  .817  .812 ± .004   .818"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_df_paper(\n",
    "    model_performance(\n",
    "        {\n",
    "            'beto': [1, 2, 3, 4, 5], \n",
    "            'beto_galen': [1, 2, 3, 4, 5],\n",
    "            'mbert': [1, 2, 3, 4, 5], \n",
    "            'mbert_galen': [1, 2, 3, 4, 5],\n",
    "            'xlmr': [1, 2, 3, 4, 5], \n",
    "            'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "        }, \n",
    "        subtask='norm'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_avg</th>\n",
       "      <th>P_std</th>\n",
       "      <th>P_max</th>\n",
       "      <th>R_avg</th>\n",
       "      <th>R_std</th>\n",
       "      <th>R_max</th>\n",
       "      <th>F1_avg</th>\n",
       "      <th>F1_std</th>\n",
       "      <th>F1_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>0.867</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             P_avg  P_std  P_max  R_avg  R_std  R_max  F1_avg  F1_std  F1_max\n",
       "beto         0.858  0.012  0.878  0.852  0.007  0.862   0.855   0.004   0.861\n",
       "beto_galen   0.864  0.006  0.871  0.865  0.005  0.871   0.865   0.003   0.868\n",
       "mbert        0.855  0.007  0.863  0.859  0.005  0.864   0.857   0.004   0.864\n",
       "mbert_galen  0.867  0.011  0.882  0.866  0.006  0.875   0.866   0.003   0.871\n",
       "xlmr         0.853  0.005  0.859  0.857  0.007  0.868   0.855   0.003   0.859\n",
       "xlmr_galen   0.865  0.008  0.878  0.866  0.004  0.870   0.865   0.003   0.869"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_performance(\n",
    "    {\n",
    "        'beto': [1, 2, 3, 4, 5], \n",
    "        'beto_galen': [1, 2, 3, 4, 5],\n",
    "        'mbert': [1, 2, 3, 4, 5], \n",
    "        'mbert_galen': [1, 2, 3, 4, 5],\n",
    "        'xlmr': [1, 2, 3, 4, 5], \n",
    "        'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "    }, \n",
    "    subtask='ner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_avg_std</th>\n",
       "      <th>P_max</th>\n",
       "      <th>R_avg_std</th>\n",
       "      <th>R_max</th>\n",
       "      <th>F1_avg_std</th>\n",
       "      <th>F1_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto</th>\n",
       "      <td>.858 ± .012</td>\n",
       "      <td>.878</td>\n",
       "      <td>.852 ± .007</td>\n",
       "      <td>.862</td>\n",
       "      <td>.855 ± .004</td>\n",
       "      <td>.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto_galen</th>\n",
       "      <td>.864 ± .006</td>\n",
       "      <td>.871</td>\n",
       "      <td>.865 ± .005</td>\n",
       "      <td>.871</td>\n",
       "      <td>.865 ± .003</td>\n",
       "      <td>.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert</th>\n",
       "      <td>.855 ± .007</td>\n",
       "      <td>.863</td>\n",
       "      <td>.859 ± .005</td>\n",
       "      <td>.864</td>\n",
       "      <td>.857 ± .004</td>\n",
       "      <td>.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbert_galen</th>\n",
       "      <td>.867 ± .011</td>\n",
       "      <td>.882</td>\n",
       "      <td>.866 ± .006</td>\n",
       "      <td>.875</td>\n",
       "      <td>.866 ± .003</td>\n",
       "      <td>.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr</th>\n",
       "      <td>.853 ± .005</td>\n",
       "      <td>.859</td>\n",
       "      <td>.857 ± .007</td>\n",
       "      <td>.868</td>\n",
       "      <td>.855 ± .003</td>\n",
       "      <td>.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlmr_galen</th>\n",
       "      <td>.865 ± .008</td>\n",
       "      <td>.878</td>\n",
       "      <td>.866 ± .004</td>\n",
       "      <td>.87</td>\n",
       "      <td>.865 ± .003</td>\n",
       "      <td>.869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               P_avg_std P_max    R_avg_std R_max   F1_avg_std F1_max\n",
       "beto         .858 ± .012  .878  .852 ± .007  .862  .855 ± .004   .861\n",
       "beto_galen   .864 ± .006  .871  .865 ± .005  .871  .865 ± .003   .868\n",
       "mbert        .855 ± .007  .863  .859 ± .005  .864  .857 ± .004   .864\n",
       "mbert_galen  .867 ± .011  .882  .866 ± .006  .875  .866 ± .003   .871\n",
       "xlmr         .853 ± .005  .859  .857 ± .007  .868  .855 ± .003   .859\n",
       "xlmr_galen   .865 ± .008  .878  .866 ± .004   .87  .865 ± .003   .869"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_df_paper(\n",
    "    model_performance(\n",
    "        {\n",
    "            'beto': [1, 2, 3, 4, 5], \n",
    "            'beto_galen': [1, 2, 3, 4, 5],\n",
    "            'mbert': [1, 2, 3, 4, 5], \n",
    "            'mbert_galen': [1, 2, 3, 4, 5],\n",
    "            'xlmr': [1, 2, 3, 4, 5], \n",
    "            'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "        }, \n",
    "        subtask='ner'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the (F1) performance of all executions of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_f1_values(dict_names_execs, subtask='norm', \n",
    "                    df_gs=df_test_gs, path_gs=test_gs_path):\n",
    "    \"\"\"\n",
    "    Generate a vector containing the F1 performance of all executions of all models, in the given order.\n",
    "    \n",
    "    dict_names_execs: each key is a string with the model name, and \n",
    "                      each value is a list with the random execs of the corresponding model.\n",
    "    \"\"\"\n",
    "    arr_values = []\n",
    "    for model_name in dict_names_execs:\n",
    "        for i_exec in dict_names_execs[model_name]:\n",
    "            df_test_preds = pd.read_csv(RES_DIR + \"df_test_preds_\" + subtask + \"_c_multi_task_\" + \\\n",
    "                    str(model_name) + \"_\" + str(i_exec) + \".csv\", header=0, sep='\\t')\n",
    "            _, _, f1 = calculate_ner_metrics(\n",
    "                gs=df_gs, \n",
    "                pred=format_ner_pred_df(\n",
    "                    gs_path=path_gs, \n",
    "                    df_preds=df_test_preds, \n",
    "                    subtask=subtask\n",
    "                ),\n",
    "                subtask=subtask\n",
    "            )\n",
    "            arr_values.append(f1)\n",
    "    return arr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_val = model_f1_values(\n",
    "    {\n",
    "        'beto': [1, 2, 3, 4, 5], \n",
    "        'beto_galen': [1, 2, 3, 4, 5],\n",
    "        'mbert': [1, 2, 3, 4, 5], \n",
    "        'mbert_galen': [1, 2, 3, 4, 5],\n",
    "        'xlmr': [1, 2, 3, 4, 5], \n",
    "        'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "    }, \n",
    "    subtask='ner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(arr_val).to_csv(RES_DIR + \"ner_f1_exec_c_multi_task.csv\", index=False, header=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_val = model_f1_values(\n",
    "    {\n",
    "        'beto': [1, 2, 3, 4, 5], \n",
    "        'beto_galen': [1, 2, 3, 4, 5],\n",
    "        'mbert': [1, 2, 3, 4, 5], \n",
    "        'mbert_galen': [1, 2, 3, 4, 5],\n",
    "        'xlmr': [1, 2, 3, 4, 5], \n",
    "        'xlmr_galen': [1, 2, 3, 4, 5]\n",
    "    }, \n",
    "    subtask='norm'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(arr_val).to_csv(RES_DIR + \"norm_f1_exec_c_multi_task.csv\", index=False, header=False, sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
